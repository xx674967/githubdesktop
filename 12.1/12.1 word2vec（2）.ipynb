{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec（2）\n",
    "#### CBOW和Skip-gram两个模型，word2vec给出了两套框架，他们分别基于Hierarchical Softmax和Negative Sampling，在Hierarchical Softmax框架下，都是以Huffman树作为基础的。\n",
    "#### 训练流程\n",
    "#### 假设我们已经有了一个已经构造好的Huffman树，以及初始化完毕的各个向量，可以开始输入文本来进行训练了。训练的过程如下图所示，主要有输入层(input)，映射层(projection)和输出层(output)三个阶段。\n",
    "![](https://github.com/xx674967/githubdesktop/blob/12/pic/11.30/4.png?raw=true)\n",
    "#### 输入层即为某个单词A周围的n-1个单词的词向量。如果n取5，则词A(可记为w(t))前两个和后两个的单词为w(t-2),w(t-1),w(t+1),w(t+2)。相对应的，那4个单词的词向量记为v(w(t-2)),v(w(t-1)),v(w(t+1)),v(w(t+2))。从输入层到映射层比较简单，将那n-1个词向量相加即可。\n",
    "#### 从映射层到输出层\n",
    "#### 要完成这一步骤，需要借助之前构造的Huffman树。从根节点开始，映射层的值需要沿着Huffman树不断的进行logistic分类，并且不断的修正各中间向量和词向量。如下图所示：\n",
    "![](https://github.com/xx674967/githubdesktop/blob/12/pic/11.30/5.png?raw=true)\n",
    "#### 此时中间的单词为w(t)，而映射层输入为  pro(t)=v(w(t-2))+v(w(t-1))+v(w(t+1))+v(w(t+2))\n",
    "#### 假设此时的单词为“足球”，即w(t)=“足球”，则其Huffman码可知为d(t)=”1001”(具体可见上一节),那么根据Huffman码可知，从根节点到叶节点的路径为“左右右左”，即从根节点开始，先往左拐，再往右拐2次，最后再左拐。既然知道了路径，那么就按照路径从上往下依次修正路径上各节点的中间向量。在第一个节点，根据节点的中间向量Θ(t,1)和pro(t)进行Logistic分类。如果分类结果显示为0，则表示分类错误(应该向左拐，即分类到1)，则要对Θ(t,1)进行修正，并记录误差量。\n",
    "#### 接下来，处理完第一个节点之后，开始处理第二个节点。方法类似，修正Θ(t,2)，并累加误差量。接下来的节点都以此类推。在处理完所有节点，达到叶节点之后，根据之前累计的误差来修正词向量v(w(t)),这样，一个词w(t)的处理流程就结束了。如果一个文本中有N个词，则需要将上述过程在重复N遍，从w(0)~w(N-1)。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pythonIDE\\anaconda\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-12-01 17:06:00,745 : INFO : collecting all words and their counts\n",
      "2017-12-01 17:06:00,773 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-12-01 17:06:07,124 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2017-12-01 17:06:07,125 : INFO : Loading a fresh vocabulary\n",
      "2017-12-01 17:06:07,515 : INFO : min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2017-12-01 17:06:07,516 : INFO : min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2017-12-01 17:06:07,795 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2017-12-01 17:06:07,816 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-12-01 17:06:07,817 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2017-12-01 17:06:07,817 : INFO : estimated required memory for 71290 words and 200 dimensions: 149709000 bytes\n",
      "2017-12-01 17:06:08,169 : INFO : resetting layer weights\n",
      "2017-12-01 17:06:09,474 : INFO : training model with 3 workers on 71290 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-12-01 17:06:10,480 : INFO : PROGRESS: at 0.86% examples, 535487 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:11,488 : INFO : PROGRESS: at 1.80% examples, 554698 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:12,494 : INFO : PROGRESS: at 2.81% examples, 578978 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:13,506 : INFO : PROGRESS: at 3.81% examples, 588117 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:14,507 : INFO : PROGRESS: at 4.81% examples, 596296 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:15,512 : INFO : PROGRESS: at 5.74% examples, 594192 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:16,527 : INFO : PROGRESS: at 6.73% examples, 597300 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:17,532 : INFO : PROGRESS: at 7.72% examples, 600782 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:18,548 : INFO : PROGRESS: at 8.68% examples, 599452 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:19,557 : INFO : PROGRESS: at 9.54% examples, 592891 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:20,566 : INFO : PROGRESS: at 10.36% examples, 585560 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:21,569 : INFO : PROGRESS: at 11.28% examples, 584760 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:22,569 : INFO : PROGRESS: at 12.26% examples, 587390 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:23,649 : INFO : PROGRESS: at 13.16% examples, 582068 words/s, in_qsize 4, out_qsize 1\n",
      "2017-12-01 17:06:24,655 : INFO : PROGRESS: at 14.10% examples, 582407 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:25,659 : INFO : PROGRESS: at 15.01% examples, 581679 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:26,660 : INFO : PROGRESS: at 15.78% examples, 574801 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:27,669 : INFO : PROGRESS: at 16.60% examples, 571053 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:28,695 : INFO : PROGRESS: at 17.18% examples, 559426 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:29,695 : INFO : PROGRESS: at 17.81% examples, 551385 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:30,700 : INFO : PROGRESS: at 18.79% examples, 553822 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:31,720 : INFO : PROGRESS: at 19.80% examples, 556705 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:32,730 : INFO : PROGRESS: at 20.80% examples, 559404 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:33,739 : INFO : PROGRESS: at 21.59% examples, 556118 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:34,749 : INFO : PROGRESS: at 22.61% examples, 559042 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:35,757 : INFO : PROGRESS: at 23.56% examples, 560271 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:36,774 : INFO : PROGRESS: at 24.59% examples, 562855 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:37,782 : INFO : PROGRESS: at 25.57% examples, 564879 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:38,784 : INFO : PROGRESS: at 26.57% examples, 567178 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:39,785 : INFO : PROGRESS: at 27.56% examples, 568968 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:40,789 : INFO : PROGRESS: at 28.35% examples, 566471 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:41,792 : INFO : PROGRESS: at 29.15% examples, 564454 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:42,802 : INFO : PROGRESS: at 29.94% examples, 562180 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:43,803 : INFO : PROGRESS: at 30.90% examples, 563484 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:44,817 : INFO : PROGRESS: at 31.86% examples, 564404 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:45,822 : INFO : PROGRESS: at 32.66% examples, 562605 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:46,831 : INFO : PROGRESS: at 33.35% examples, 558836 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:47,858 : INFO : PROGRESS: at 33.74% examples, 550417 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:48,882 : INFO : PROGRESS: at 34.26% examples, 544402 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:49,892 : INFO : PROGRESS: at 35.29% examples, 546349 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:50,926 : INFO : PROGRESS: at 36.12% examples, 545177 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:51,931 : INFO : PROGRESS: at 36.81% examples, 542487 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:52,936 : INFO : PROGRESS: at 37.59% examples, 541066 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:53,940 : INFO : PROGRESS: at 38.57% examples, 542550 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:54,959 : INFO : PROGRESS: at 39.46% examples, 542618 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:06:55,958 : INFO : PROGRESS: at 40.39% examples, 543408 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:56,968 : INFO : PROGRESS: at 41.41% examples, 545135 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:06:57,980 : INFO : PROGRESS: at 42.33% examples, 545509 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:06:58,980 : INFO : PROGRESS: at 43.33% examples, 547101 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:00,003 : INFO : PROGRESS: at 44.36% examples, 548837 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:01,011 : INFO : PROGRESS: at 45.24% examples, 548918 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:02,019 : INFO : PROGRESS: at 46.26% examples, 550568 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:03,028 : INFO : PROGRESS: at 47.27% examples, 552168 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:04,041 : INFO : PROGRESS: at 48.22% examples, 552823 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:05,045 : INFO : PROGRESS: at 49.23% examples, 554276 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:06,044 : INFO : PROGRESS: at 50.21% examples, 555319 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:07:07,048 : INFO : PROGRESS: at 51.13% examples, 555781 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:08,059 : INFO : PROGRESS: at 52.09% examples, 556397 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:09,062 : INFO : PROGRESS: at 53.02% examples, 556768 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:10,070 : INFO : PROGRESS: at 53.90% examples, 556638 words/s, in_qsize 5, out_qsize 1\n",
      "2017-12-01 17:07:11,072 : INFO : PROGRESS: at 54.89% examples, 557679 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:12,072 : INFO : PROGRESS: at 55.91% examples, 558692 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:07:13,079 : INFO : PROGRESS: at 56.86% examples, 559198 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:14,080 : INFO : PROGRESS: at 57.86% examples, 560224 words/s, in_qsize 5, out_qsize 1\n",
      "2017-12-01 17:07:15,080 : INFO : PROGRESS: at 58.81% examples, 560680 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:16,104 : INFO : PROGRESS: at 59.79% examples, 561174 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:17,112 : INFO : PROGRESS: at 60.79% examples, 562054 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:18,117 : INFO : PROGRESS: at 61.81% examples, 562999 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:19,131 : INFO : PROGRESS: at 62.76% examples, 563336 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:20,132 : INFO : PROGRESS: at 63.77% examples, 564282 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:21,150 : INFO : PROGRESS: at 64.76% examples, 564952 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:22,166 : INFO : PROGRESS: at 65.55% examples, 563878 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:23,168 : INFO : PROGRESS: at 66.34% examples, 562973 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:24,192 : INFO : PROGRESS: at 67.27% examples, 563141 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:25,197 : INFO : PROGRESS: at 68.08% examples, 562345 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:26,222 : INFO : PROGRESS: at 69.09% examples, 563115 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:27,239 : INFO : PROGRESS: at 69.98% examples, 562978 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:28,251 : INFO : PROGRESS: at 70.78% examples, 562109 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:29,263 : INFO : PROGRESS: at 71.65% examples, 561826 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:30,270 : INFO : PROGRESS: at 72.62% examples, 562308 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:31,269 : INFO : PROGRESS: at 73.35% examples, 561009 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:32,273 : INFO : PROGRESS: at 74.31% examples, 561543 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:33,282 : INFO : PROGRESS: at 75.33% examples, 562264 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:34,289 : INFO : PROGRESS: at 76.34% examples, 562971 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:35,292 : INFO : PROGRESS: at 77.30% examples, 563338 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:36,299 : INFO : PROGRESS: at 78.31% examples, 564066 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:37,302 : INFO : PROGRESS: at 79.31% examples, 564702 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:38,305 : INFO : PROGRESS: at 80.32% examples, 565413 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:39,310 : INFO : PROGRESS: at 81.34% examples, 566120 words/s, in_qsize 4, out_qsize 0\n",
      "2017-12-01 17:07:40,316 : INFO : PROGRESS: at 82.34% examples, 566683 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:41,321 : INFO : PROGRESS: at 83.33% examples, 567194 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:42,332 : INFO : PROGRESS: at 84.34% examples, 567841 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:43,341 : INFO : PROGRESS: at 85.33% examples, 568374 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:44,347 : INFO : PROGRESS: at 86.34% examples, 569100 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:45,360 : INFO : PROGRESS: at 87.30% examples, 569451 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:46,366 : INFO : PROGRESS: at 88.28% examples, 569836 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:47,370 : INFO : PROGRESS: at 89.27% examples, 570328 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:48,373 : INFO : PROGRESS: at 90.26% examples, 570891 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:49,373 : INFO : PROGRESS: at 91.25% examples, 571407 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:50,381 : INFO : PROGRESS: at 92.24% examples, 571830 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:51,386 : INFO : PROGRESS: at 93.22% examples, 572174 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:52,390 : INFO : PROGRESS: at 94.22% examples, 572702 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:53,397 : INFO : PROGRESS: at 95.23% examples, 573148 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:54,404 : INFO : PROGRESS: at 96.24% examples, 573595 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:55,411 : INFO : PROGRESS: at 97.20% examples, 573840 words/s, in_qsize 6, out_qsize 0\n",
      "2017-12-01 17:07:56,425 : INFO : PROGRESS: at 98.21% examples, 574304 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:57,433 : INFO : PROGRESS: at 99.20% examples, 574636 words/s, in_qsize 5, out_qsize 0\n",
      "2017-12-01 17:07:58,202 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-12-01 17:07:58,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-12-01 17:07:58,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-12-01 17:07:58,210 : INFO : training on 85026035 raw words (62529413 effective words) took 108.7s, 575072 effective words/s\n",
      "2017-12-01 17:07:58,211 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman和man的相似度为： 0.69904747399\n",
      "--------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-01 17:07:58,697 : INFO : saving Word2Vec object under text8.model, separately None\n",
      "2017-12-01 17:07:58,698 : INFO : storing np array 'syn0' to text8.model.wv.syn0.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和good最相关的词有：\n",
      "\n",
      "bad 0.7356971502304077\n",
      "poor 0.5622576475143433\n",
      "quick 0.5398947596549988\n",
      "safe 0.5122597813606262\n",
      "happy 0.5090628266334534\n",
      "reasonable 0.5070134401321411\n",
      "luck 0.5024716258049011\n",
      "everyone 0.5022332668304443\n",
      "courage 0.49608728289604187\n",
      "easy 0.48916977643966675\n",
      "really 0.48791834712028503\n",
      "pleasant 0.4867483377456665\n",
      "helpful 0.4853461682796478\n",
      "simple 0.4842473268508911\n",
      "you 0.48311030864715576\n",
      "pleasure 0.47916221618652344\n",
      "fun 0.47735875844955444\n",
      "practical 0.4723237156867981\n",
      "sick 0.46949368715286255\n",
      "true 0.4688076972961426\n",
      "--------\n",
      "\n",
      " \"boy\" is to \"father\" as \"girl\" is to ...? \n",
      "\n",
      "mother 0.755297064781189\n",
      "wife 0.7149423360824585\n",
      "lover 0.7115675210952759\n",
      "--------\n",
      "\n",
      "'he' is to 'his' as 'she' is to 'her'\n",
      "'big' is to 'bigger' as 'bad' is to 'worse'\n",
      "'going' is to 'went' as 'being' is to 'was'\n",
      "--------\n",
      "\n",
      "不合群的词： cereal\n",
      "--------\n",
      "\n",
      "man的向量表示为: [ 2.84990549  1.66100156 -0.46291554 -1.91552424  1.26991677 -0.53002125\n",
      " -1.65775323  0.16581546 -0.37104455 -0.66493225 -2.68795276 -0.98964429\n",
      "  0.74027175  0.83170462  0.3797133  -0.36564422  0.78618819  0.33085719\n",
      "  0.44892898  0.78222984 -0.07527302  1.03882289 -1.99759102  1.85718942\n",
      "  2.02364588 -1.10365534  0.28239825 -0.72019976 -1.19803905  0.16315424\n",
      " -1.0026269   0.2484477   0.05102041  0.96586782  1.96214306 -2.19951439\n",
      "  0.82643902 -0.63883281 -0.91182375 -0.25428298  1.67938423 -0.45735824\n",
      " -0.07179473 -1.43522036  0.82111633 -0.18213077 -1.57648122 -0.71429247\n",
      "  0.36937949  0.25324577  0.31357452 -2.4207077  -0.0241117  -1.16797972\n",
      " -0.36098364  1.32045281  0.06746813  1.95746458  0.56274533  0.21990137\n",
      " -0.01401138  0.0574321   0.74110878 -0.67924148  0.12583764  1.28794312\n",
      " -1.37125194 -0.36716914 -0.08332597 -0.00648012  0.73951912 -0.36574325\n",
      " -0.37524316  0.65838474 -0.03875465 -1.91973841  2.54757881 -0.23880376\n",
      "  1.2057147   0.15767473 -1.08966947  0.0893077  -1.56538272  0.56243378\n",
      "  1.65325069 -0.26697111 -2.59878588  0.70056093 -0.78137916 -0.29614526\n",
      " -1.08889115  0.1567004   2.73792458  0.32043281  1.57779479  0.91225725\n",
      " -1.29899573 -1.18947673  0.47628629  0.54619694  2.03044605  0.69340295\n",
      " -4.02926826  1.31876552  0.59756422  0.43669066 -0.2351674   2.04298019\n",
      " -1.08337343  0.16523911  0.11295541 -0.52283877  0.01653624 -0.6800226\n",
      " -1.60326898  0.16517779 -1.72382617 -0.12129626  0.30450955  0.31627643\n",
      " -1.78943527  0.83437347  0.80744553 -0.62053263 -0.03210693  1.87041306\n",
      "  2.54749107 -0.74052823 -0.00697328  1.22935104  0.20483659  0.79514205\n",
      " -1.25847864 -2.25778866 -0.21078563 -1.23147273  0.04141822  0.66311818\n",
      "  0.43974233  1.46699226 -1.10270834  0.40597135  0.17748524  0.1116393\n",
      "  0.35730216 -0.43965364  1.25133801  0.44471493 -0.91631937 -2.30782151\n",
      "  1.3230077  -0.02770869 -0.58097899  0.34591112  0.21906033  0.36910716\n",
      " -1.18284619  0.68745226  1.17708778  0.23736008  1.04062402  2.32370615\n",
      "  0.27462149  0.30262631  0.79007256  1.97054112  0.41340321  0.42966101\n",
      "  0.1281496  -0.56907415  0.48163703 -1.56017959  0.13180627 -0.55732781\n",
      "  0.12361874 -1.78840733 -0.61660272 -1.19609678  0.90965474  0.6987524\n",
      "  0.17657876  1.22346163  0.05764034  1.02960694 -0.29207236 -0.65047288\n",
      "  0.26938149  1.29409564 -0.0189758   0.02583921  1.06250405  0.07345543\n",
      " -0.52778798 -0.64760524  0.39429808  0.07163052  0.5894075  -0.68703949\n",
      " -0.20962349 -1.10046709]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-01 17:07:59,107 : INFO : not storing attribute syn0norm\n",
      "2017-12-01 17:07:59,108 : INFO : storing np array 'syn1neg' to text8.model.syn1neg.npy\n",
      "2017-12-01 17:07:59,502 : INFO : not storing attribute cum_table\n",
      "2017-12-01 17:07:59,753 : INFO : saved text8.model\n"
     ]
    },
    {
     "ename": "DeprecationWarning",
     "evalue": "Deprecated. Use model.wv.save_word2vec_format instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d4f14544ee93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[1;31m# 以一种C语言可以解析的形式存储词向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text8.model.bin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[1;31m# 对应的加载方式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[1;31m# model_3 = word2vec.Word2Vec.load_word2vec_format(\"text8.model.bin\", binary=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\pythonIDE\\anaconda\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36msave_word2vec_format\u001b[0;34m(self, fname, fvocab, binary)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[1;34m\"\"\"Deprecated. Use model.wv.save_word2vec_format instead.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Deprecated. Use model.wv.save_word2vec_format instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_latest_training_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: Deprecated. Use model.wv.save_word2vec_format instead."
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Dec  1 16:05:09 2017\n",
    "\n",
    "@author: XZ\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "\n",
    "# 主程序\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus(u\"E:\\\\ImageCaption\\\\ImageCaption\\\\text8\")  # 加载语料\n",
    "model = word2vec.Word2Vec(sentences, size=200)  # 训练skip-gram模型; 默认window=5\n",
    "\n",
    "# 计算两个词的相似度/相关程度\n",
    "y1 = model.similarity(\"woman\", \"man\")\n",
    "print (u\"woman和man的相似度为：\", y1)\n",
    "print (\"--------\\n\")\n",
    "\n",
    "# 计算某个词的相关词列表\n",
    "y2 = model.most_similar(\"good\", topn=20)  # 20个最相关的\n",
    "print (u\"和good最相关的词有：\\n\")\n",
    "for item in y2:\n",
    "    print (item[0], item[1])\n",
    "print (\"--------\\n\")\n",
    "\n",
    "# 寻找对应关系\n",
    "print (' \"boy\" is to \"father\" as \"girl\" is to ...? \\n')\n",
    "y3 = model.most_similar(['girl', 'father'], ['boy'], topn=3)\n",
    "for item in y3:\n",
    "    print (item[0], item[1])\n",
    "print (\"--------\\n\")\n",
    "\n",
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.most_similar([x, b], [a])[0][0]\n",
    "    print (\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))\n",
    "print (\"--------\\n\")\n",
    "\n",
    "# 寻找不合群的词\n",
    "y4 = model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "print (u\"不合群的词：\", y4)\n",
    "print (\"--------\\n\")\n",
    "\n",
    "#具体的单词向量\n",
    "y5 = model['man']\n",
    "print(u'man的向量表示为:',y5)\n",
    "\n",
    "# 保存模型，以便重用\n",
    "model.save(\"text8.model\")\n",
    "# 对应的加载方式\n",
    "# model_2 = word2vec.Word2Vec.load(\"text8.model\")\n",
    "\n",
    "# 以一种C语言可以解析的形式存储词向量\n",
    "model.save_word2vec_format(\"text8.model.bin\", binary=True)\n",
    "# 对应的加载方式\n",
    "# model_3 = word2vec.Word2Vec.load_word2vec_format(\"text8.model.bin\", binary=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预料\n",
    "![](https://github.com/xx674967/githubdesktop/blob/12/pic/11.30/6.png?raw=true)\n",
    "\n",
    "## 运行结果：\n",
    "\n",
    "## woman和man的相似度为： 0.69904747399\n",
    "\n",
    "\n",
    "2017-12-01 17:07:58,697 : INFO : saving Word2Vec object under text8.model, separately None\n",
    "2017-12-01 17:07:58,698 : INFO : storing np array 'syn0' to text8.model.wv.syn0.npy\n",
    "## 和good最相关的词有：\n",
    "\n",
    "#### bad 0.7356971502304077\n",
    "#### poor 0.5622576475143433\n",
    "#### quick 0.5398947596549988\n",
    "#### safe 0.5122597813606262\n",
    "#### happy 0.5090628266334534\n",
    "#### reasonable 0.5070134401321411\n",
    "#### luck 0.5024716258049011\n",
    "#### everyone 0.5022332668304443\n",
    "#### courage 0.49608728289604187\n",
    "#### easy 0.48916977643966675\n",
    "#### really 0.48791834712028503\n",
    "#### pleasant 0.4867483377456665\n",
    "#### helpful 0.4853461682796478\n",
    "#### simple 0.4842473268508911\n",
    "#### you 0.48311030864715576\n",
    "#### pleasure 0.47916221618652344\n",
    "#### fun 0.47735875844955444\n",
    "#### practical 0.4723237156867981\n",
    "#### sick 0.46949368715286255\n",
    "#### true 0.4688076972961426\n",
    "\n",
    "\n",
    "##  \"boy\" is to \"father\" as \"girl\" is to ...? \n",
    "\n",
    "#### mother 0.755297064781189 wife 0.7149423360824585 lover 0.7115675210952759\n",
    "\n",
    "\n",
    "#### 'he' is to 'his' as 'she' is to 'her'\n",
    "##### 'big' is to 'bigger' as 'bad' is to 'worse'\n",
    "##### 'going' is to 'went' as 'being' is to 'was'\n",
    "\n",
    "\n",
    "## 不合群的词： cereal\n",
    "\n",
    "\n",
    "## man的向量表示为: \n",
    "\n",
    "\n",
    "[ 2.84990549  1.66100156 -0.46291554 -1.91552424  1.26991677 -0.53002125\n",
    " -1.65775323  0.16581546 -0.37104455 -0.66493225 -2.68795276 -0.98964429\n",
    "  0.74027175  0.83170462  0.3797133  -0.36564422  0.78618819  0.33085719\n",
    "  0.44892898  0.78222984 -0.07527302  1.03882289 -1.99759102  1.85718942\n",
    "  2.02364588 -1.10365534  0.28239825 -0.72019976 -1.19803905  0.16315424\n",
    " -1.0026269   0.2484477   0.05102041  0.96586782  1.96214306 -2.19951439\n",
    "  0.82643902 -0.63883281 -0.91182375 -0.25428298  1.67938423 -0.45735824\n",
    " -0.07179473 -1.43522036  0.82111633 -0.18213077 -1.57648122 -0.71429247\n",
    "  0.36937949  0.25324577  0.31357452 -2.4207077  -0.0241117  -1.16797972\n",
    " -0.36098364  1.32045281  0.06746813  1.95746458  0.56274533  0.21990137\n",
    " -0.01401138  0.0574321   0.74110878 -0.67924148  0.12583764  1.28794312\n",
    " -1.37125194 -0.36716914 -0.08332597 -0.00648012  0.73951912 -0.36574325\n",
    " -0.37524316  0.65838474 -0.03875465 -1.91973841  2.54757881 -0.23880376\n",
    "  1.2057147   0.15767473 -1.08966947  0.0893077  -1.56538272  0.56243378\n",
    "  1.65325069 -0.26697111 -2.59878588  0.70056093 -0.78137916 -0.29614526\n",
    " -1.08889115  0.1567004   2.73792458  0.32043281  1.57779479  0.91225725\n",
    " -1.29899573 -1.18947673  0.47628629  0.54619694  2.03044605  0.69340295\n",
    " -4.02926826  1.31876552  0.59756422  0.43669066 -0.2351674   2.04298019\n",
    " -1.08337343  0.16523911  0.11295541 -0.52283877  0.01653624 -0.6800226\n",
    " -1.60326898  0.16517779 -1.72382617 -0.12129626  0.30450955  0.31627643\n",
    " -1.78943527  0.83437347  0.80744553 -0.62053263 -0.03210693  1.87041306\n",
    "  2.54749107 -0.74052823 -0.00697328  1.22935104  0.20483659  0.79514205\n",
    " -1.25847864 -2.25778866 -0.21078563 -1.23147273  0.04141822  0.66311818\n",
    "  0.43974233  1.46699226 -1.10270834  0.40597135  0.17748524  0.1116393\n",
    "  0.35730216 -0.43965364  1.25133801  0.44471493 -0.91631937 -2.30782151\n",
    "  1.3230077  -0.02770869 -0.58097899  0.34591112  0.21906033  0.36910716\n",
    " -1.18284619  0.68745226  1.17708778  0.23736008  1.04062402  2.32370615\n",
    "  0.27462149  0.30262631  0.79007256  1.97054112  0.41340321  0.42966101\n",
    "  0.1281496  -0.56907415  0.48163703 -1.56017959  0.13180627 -0.55732781\n",
    "  0.12361874 -1.78840733 -0.61660272 -1.19609678  0.90965474  0.6987524\n",
    "  0.17657876  1.22346163  0.05764034  1.02960694 -0.29207236 -0.65047288\n",
    "  0.26938149  1.29409564 -0.0189758   0.02583921  1.06250405  0.07345543\n",
    " -0.52778798 -0.64760524  0.39429808  0.07163052  0.5894075  -0.68703949\n",
    " -0.20962349 -1.10046709]\n",
    " ## 模型保存\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
